\chapter{Contributions for the LHCb collaboration} % (fold)
\label{cha:contribution_for_the_lhcb_collaboration}

Beyond the data analysis and phenomenology work that I have performed, I have made numerous other contributions to the LHCb experiment. I have undertaken shift work as a RICH piquet and as a Data Manager. For two years, I was the liaison between the PID-performance working group and the \emph{beauty-to-open-charm} (B2OC) physics working group, ensuring that relevant news and updates were communicated between the working groups. The exchange of this information is critical, since the PID calibration is updated regularly during data-taking,  and reprocessed in case that issues are found. Furthermore, liaisons from different physics working groups come together in the performance working group, and therefore I was able to showcase ideas or problems from elsewhere in the collaboration for the benefit of analysts in the B2OC working group. As a part of this role, I performed validation work calibration for data samples collected during Run~2.  

Preparations for Run 3 of the LHC are well under way. A major part of the \lhcb upgrade is the evolution of the trigger system.  With an average of seven $pp$ interactions per bunch crossing in the upgrade, an event is very likely to have either a $b\bar b$ or $c\bar c$ pair produced. However, the bandwidth for data to be stored to disk is limited. Therefore, the role of trigger becomes that of separating \emph{interesting} signal decays from other signal decays, rather than simply separating signal decays from background. This will be achieved by making the trigger entirely software-based, based on a readout of the whole detector in order to make even the first level of selections.  Furthermore, the second layer of the software trigger will perform the full, offline-quality reconstruction, but still need to be fast enough to process the data before the disk buffer is exceeded. During Run~2, most analyses were based on data selected via inclusive triggering, with the centralised stripping stage applied subsequently to select the signals of interest for specific analyses. In Run~3, the ambition is to run the equivalent of the stripping stage already in the second stage of the software trigger. This will allow for better selections in the trigger and for only saving information related to signal decays, rather than the full event information; both crucial points for optimising the signal rate given a limited band width. 

Amongst the working groups, B2OC is unique in having a single code module that handles a large number of decay channels (approx 800 in total) in the stripping stage. I took the role as \emph{migration coordinator}\footnote{Along with Alessandro Bertolin and Shunan Zhang.}, responsible for developing the equivalent functionality within the new trigger framework, to be run during the \lhcb upgrade. The motivation behind a centralised selection module is to exploit the similarities between many B2OC selections to stay within timing and bandwidth limitations; for example, candidates for specific $D$ decays are formed once and subsequently used in many different selections of $\B\to\D X$ decay candidates. This fundamental design choice was kept in the new B2OC module, but apart from that it was redesigned and written from scratch, in order to follow the functional programming paradigm of the new trigger frame work and to simultaneously allow authors of individual selections to make use of the centrally defined candidates for performance reasons, while providing optimal flexibility for making analysis-specific choices without impacting other selections. I took a leading role in the initial design and testing of the new B2OC module, and helped the first analysts implement analysis-specific selections within it.


% chapter contribution_for_the_lhcb_collaboration (end)